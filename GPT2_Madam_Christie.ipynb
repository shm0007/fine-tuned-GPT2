{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90d4ea282bd34a06aa5925dbcc2a4daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1c44f67a9eb41e7aa0738d565f2d3a8",
              "IPY_MODEL_6abb797114ff4333a6378904f65c60a6",
              "IPY_MODEL_ed0fd6f2c151476ebc52a49eab5b3fd3",
              "IPY_MODEL_f7e1ce98649e44eb9b37b220a433045b",
              "IPY_MODEL_64b62a754d634f499320660aaa5140a7"
            ],
            "layout": "IPY_MODEL_ed64fbfe5ba24afd891670f87ed3b2c0"
          }
        },
        "b1c44f67a9eb41e7aa0738d565f2d3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11d5bd94f4ae477e905e491c5be4d259",
            "placeholder": "​",
            "style": "IPY_MODEL_f2767de3b13046b8b0b425665c9e4671",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "6abb797114ff4333a6378904f65c60a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_cb592b8a9ef645c1b46cc4baa7dc48bf",
            "placeholder": "​",
            "style": "IPY_MODEL_8549a3f78dcd41588361d77bca911089",
            "value": ""
          }
        },
        "ed0fd6f2c151476ebc52a49eab5b3fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_cf211485df244ab3902c840f37054978",
            "style": "IPY_MODEL_11002102c6e840288415f7e4a32e2f90",
            "value": true
          }
        },
        "f7e1ce98649e44eb9b37b220a433045b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8d97e6a28a484bc09d8c046a21e7795b",
            "style": "IPY_MODEL_47558a3a8bcd4364a70dc3d42e9ec6c2",
            "tooltip": ""
          }
        },
        "64b62a754d634f499320660aaa5140a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd93c4250e2c47a2aea15d40572a65e0",
            "placeholder": "​",
            "style": "IPY_MODEL_a343a2a3ee33452bb05989af949fe41f",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "ed64fbfe5ba24afd891670f87ed3b2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "11d5bd94f4ae477e905e491c5be4d259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2767de3b13046b8b0b425665c9e4671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb592b8a9ef645c1b46cc4baa7dc48bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8549a3f78dcd41588361d77bca911089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf211485df244ab3902c840f37054978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11002102c6e840288415f7e4a32e2f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d97e6a28a484bc09d8c046a21e7795b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47558a3a8bcd4364a70dc3d42e9ec6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "dd93c4250e2c47a2aea15d40572a65e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a343a2a3ee33452bb05989af949fe41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shm0007/fine-tuned-GPT2/blob/main/GPT2_Madam_Christie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine Tuned GPT2\n",
        "## 02/22/22\n",
        "Fine tuned version of GPT-2 with a text corpus consists of Agatha Christies novel.  \n"
      ],
      "metadata": {
        "id": "DJn17r6mKk5Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulXhSm8PmzI5"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download the corpus zip file and unzip\n",
        "!wget --no-check-certificate https://github.com/shm0007/corpus-crime/raw/main/corpus.zip\n",
        "!unzip corpus.zip"
      ],
      "metadata": {
        "id": "loylpvlvm3np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r corpus"
      ],
      "metadata": {
        "id": "5dj6IUyTx5cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "#get the file names and path from the corpus\n",
        "current_path = os.getcwd()\n",
        "os.listdir(current_path + \"/corpus\" )\n",
        "filepaths = os.listdir(current_path + \"/corpus\" )\n",
        "\n",
        "data = []\n",
        "\n",
        "#str to store all the file names. Used it late to run with wc and getting token count\n",
        "filenames  = \"\"\n",
        "\n",
        "#loop through each file, preprocess and add to data\n",
        "for fl in filepaths:\n",
        "  f = open(\"corpus/\" + fl)\n",
        "  filenames += (\" corpus/\" +fl)\n",
        "  file_text = f.read()\n",
        "  f.close()\n",
        "\n",
        "  #replace unnesessary characters with whitespace\n",
        "  file_text = file_text.replace(\"\\n\", \" \")\n",
        "  file_text = file_text.replace(\"=\", \" \")\n",
        "  file_text = file_text.replace(\"“\", \" \")\n",
        "  file_text = file_text.replace(\"”\", \" \")\n",
        "  sentences = sent_tokenize(file_text)\n",
        "  for sentence in sentences:\n",
        "    if(len(sentence) > 200): # remove sentences that are too long\n",
        "      continue\n",
        "    data.append(sentence)\n",
        "\n",
        "train, test = train_test_split(data,test_size=0.15) #85 percent train, 15% validation\n",
        "print(len(data))\n",
        "print(len(train))\n",
        "print(len(test))\n",
        "\n",
        "#modified the function according to purpose, just kept the name same as the reference tutorial\n",
        "def build_text_files(dt, dest_path):\n",
        "    f = open(dest_path, 'w')\n",
        "    data = ''\n",
        "    for line in dt:\n",
        "        data += line\n",
        "        #add a new line to the end of each sentence. Removing it increases training and validation loss.\n",
        "        data += \"\\n\"\n",
        "    f.write(data)\n",
        "\n",
        "build_text_files(train,'train_dataset.txt')\n",
        "build_text_files(test,'test_dataset.txt')\n",
        "\n",
        "#print(filenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYDVVOtOnBWD",
        "outputId": "b7f3c0c3-3384-4c66-f7f0-dc1661a6ea87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The_Secret_of_Chimneys.txt\n",
            "And_Then_There_Were_None.txt\n",
            "The_Hunters_Lodge_Case.txt\n",
            "The_Big_Four.txt\n",
            "The_Man_in_the_Brown_Suit.txt\n",
            "The_Secret_Adversary.txt\n",
            "The_Mysterious_Affair_at_Styles.txt\n",
            "The_Plymouth_Express_Affair.txt\n",
            "The_Mystery_of_the_Blue_Train.txt\n",
            "The_Murder_on_the_Links.txt\n",
            "The_murder_of_Roger_Ackroyd.txt\n",
            "Poirot_Investigates.txt\n",
            "The_Missing_Will.txt\n",
            "Large0\n",
            "63258\n",
            "53769\n",
            "9489\n",
            " corpus/The_Secret_of_Chimneys.txt corpus/And_Then_There_Were_None.txt corpus/The_Hunters_Lodge_Case.txt corpus/The_Big_Four.txt corpus/The_Man_in_the_Brown_Suit.txt corpus/The_Secret_Adversary.txt corpus/The_Mysterious_Affair_at_Styles.txt corpus/The_Plymouth_Express_Affair.txt corpus/The_Mystery_of_the_Blue_Train.txt corpus/The_Murder_on_the_Links.txt corpus/The_murder_of_Roger_Ackroyd.txt corpus/Poirot_Investigates.txt corpus/The_Missing_Will.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read the word count for each of the book after pre processing\n",
        "!wc corpus/The_Murder_on_the_Links.txt corpus/The_Hunters_Lodge_Case.txt corpus/The_Missing_Will.txt corpus/The_Mysterious_Affair_at_Styles.txt corpus/The_Secret_of_Chimneys.txt corpus/And_Then_There_Were_None.txt corpus/The_murder_of_Roger_Ackroyd.txt corpus/Poirot_Investigates.txt corpus/The_Big_Four.txt corpus/The_Mystery_of_the_Blue_Train.txt corpus/The_Plymouth_Express_Affair.txt corpus/The_Secret_Adversary.txt corpus/The_Man_in_the_Brown_Suit.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFGcGgF_7eY8",
        "outputId": "8817fbbd-1e91-47d1-a2f7-ef2692566e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   9217   64470  383665 corpus/The_Murder_on_the_Links.txt\n",
            "    574    4352   25602 corpus/The_Hunters_Lodge_Case.txt\n",
            "    409    3257   19004 corpus/The_Missing_Will.txt\n",
            "   8488   56456  341202 corpus/The_Mysterious_Affair_at_Styles.txt\n",
            "  11399   74431  455894 corpus/The_Secret_of_Chimneys.txt\n",
            "   7988   52607  320398 corpus/And_Then_There_Were_None.txt\n",
            "  10355   69485  416920 corpus/The_murder_of_Roger_Ackroyd.txt\n",
            "   7494   52494  313466 corpus/Poirot_Investigates.txt\n",
            "   4227   55230  319360 corpus/The_Big_Four.txt\n",
            "   7214   71222  414922 corpus/The_Mystery_of_the_Blue_Train.txt\n",
            "    719    4858   29493 corpus/The_Plymouth_Express_Affair.txt\n",
            "  10855   75138  452531 corpus/The_Secret_Adversary.txt\n",
            "  10317   75261  435752 corpus/The_Man_in_the_Brown_Suit.txt\n",
            "  89256  659261 3928209 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc train_dataset.txt test_dataset.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6yoaImUpIS6",
        "outputId": "08d9a69f-d2bc-4983-f977-4f2e855297d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  53786  536748 2991664 train_dataset.txt\n",
            "   9492   94080  524372 test_dataset.txt\n",
            "  63278  630828 3516036 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This block is used as is in the tutorial. Found out that TextDataset is old approach,\n",
        "# tried with other methods, but couldn't make it with other methods.\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import GPT2Tokenizer, GPT2Model,DataCollatorWithPadding\n",
        "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "train_path = 'train_dataset.txt'\n",
        "test_path = 'test_dataset.txt'\n",
        "\n",
        "\n",
        "\n",
        "def load_dataset(train_path,test_path,tokenizer):\n",
        "    train_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=train_path,\n",
        "          block_size=128)\n",
        "     \n",
        "    test_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=test_path,\n",
        "          block_size=128)   \n",
        "    \n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False,\n",
        "    )\n",
        "    return train_dataset,test_dataset,data_collator\n",
        "\n",
        "train_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,tokenizer)"
      ],
      "metadata": {
        "id": "0Ka0P9h7nDrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For logging to huggingface hub for pushing the model\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "YMjsBcysw07C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "90d4ea282bd34a06aa5925dbcc2a4daf",
            "b1c44f67a9eb41e7aa0738d565f2d3a8",
            "6abb797114ff4333a6378904f65c60a6",
            "ed0fd6f2c151476ebc52a49eab5b3fd3",
            "f7e1ce98649e44eb9b37b220a433045b",
            "64b62a754d634f499320660aaa5140a7",
            "ed64fbfe5ba24afd891670f87ed3b2c0",
            "11d5bd94f4ae477e905e491c5be4d259",
            "f2767de3b13046b8b0b425665c9e4671",
            "cb592b8a9ef645c1b46cc4baa7dc48bf",
            "8549a3f78dcd41588361d77bca911089",
            "cf211485df244ab3902c840f37054978",
            "11002102c6e840288415f7e4a32e2f90",
            "8d97e6a28a484bc09d8c046a21e7795b",
            "47558a3a8bcd4364a70dc3d42e9ec6c2",
            "dd93c4250e2c47a2aea15d40572a65e0",
            "a343a2a3ee33452bb05989af949fe41f"
          ]
        },
        "outputId": "98aa625b-600a-46a2-d11c-a3697cdab53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90d4ea282bd34a06aa5925dbcc2a4daf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#for clearing the gpu cache\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "wkCwVjCXsWXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments,AutoModelWithLMHead,GPT2Model,PretrainedConfig\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
        "\n",
        "#modified some Traning Argument from the tutorial for better performance/see result\n",
        "training_args = TrainingArguments(\n",
        "    \"gpt2-finetuned-agatha-christie\", #The model name\n",
        "    push_to_hub=True, #to push it directly while training\n",
        "    save_strategy=\"steps\", # it is saving after 50 steps\n",
        "    evaluation_strategy = \"steps\", #after 'eval_steps\" steps, it will evaluate\n",
        "    num_train_epochs=6, # number of training epochs\n",
        "    per_device_train_batch_size=32, # batch size for training\n",
        "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
        "    eval_steps = 50, # Number of update steps between two evaluations.\n",
        "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
        "    logging_steps=50\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "58KiUdHenHn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2587
        },
        "id": "yvHd4O5Q4z-7",
        "outputId": "2d4f25c9-2a65-4ec8-ed09-84de2fe6ceb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 6216\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1170\n",
            "  Number of trainable parameters = 124439808\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1170/1170 26:33, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>4.282400</td>\n",
              "      <td>3.876366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.882400</td>\n",
              "      <td>3.593053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>3.633600</td>\n",
              "      <td>3.437750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.505600</td>\n",
              "      <td>3.344468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>3.403800</td>\n",
              "      <td>3.288068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>3.350200</td>\n",
              "      <td>3.250618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>3.313500</td>\n",
              "      <td>3.222385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>3.283900</td>\n",
              "      <td>3.202802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>3.219300</td>\n",
              "      <td>3.181643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.206600</td>\n",
              "      <td>3.165961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>3.204300</td>\n",
              "      <td>3.146952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.161900</td>\n",
              "      <td>3.137962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>3.109200</td>\n",
              "      <td>3.127134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.107300</td>\n",
              "      <td>3.118670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>3.099000</td>\n",
              "      <td>3.110854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.069500</td>\n",
              "      <td>3.108934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>3.028100</td>\n",
              "      <td>3.104440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>3.032200</td>\n",
              "      <td>3.100215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>3.035800</td>\n",
              "      <td>3.094390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.012600</td>\n",
              "      <td>3.095834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>2.988900</td>\n",
              "      <td>3.093143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>2.987400</td>\n",
              "      <td>3.091735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>2.991500</td>\n",
              "      <td>3.091083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to gpt2-finetuned-agatha-christie/checkpoint-500\n",
            "Configuration saved in gpt2-finetuned-agatha-christie/checkpoint-500/config.json\n",
            "Configuration saved in gpt2-finetuned-agatha-christie/checkpoint-500/generation_config.json\n",
            "Model weights saved in gpt2-finetuned-agatha-christie/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in gpt2-finetuned-agatha-christie/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in gpt2-finetuned-agatha-christie/checkpoint-500/special_tokens_map.json\n",
            "tokenizer config file saved in gpt2-finetuned-agatha-christie/tokenizer_config.json\n",
            "Special tokens file saved in gpt2-finetuned-agatha-christie/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to gpt2-finetuned-agatha-christie/checkpoint-1000\n",
            "Configuration saved in gpt2-finetuned-agatha-christie/checkpoint-1000/config.json\n",
            "Configuration saved in gpt2-finetuned-agatha-christie/checkpoint-1000/generation_config.json\n",
            "Model weights saved in gpt2-finetuned-agatha-christie/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in gpt2-finetuned-agatha-christie/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in gpt2-finetuned-agatha-christie/checkpoint-1000/special_tokens_map.json\n",
            "tokenizer config file saved in gpt2-finetuned-agatha-christie/tokenizer_config.json\n",
            "Special tokens file saved in gpt2-finetuned-agatha-christie/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1097\n",
            "  Batch size = 64\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1170, training_loss=3.2522835560334036, metrics={'train_runtime': 1597.1331, 'train_samples_per_second': 23.352, 'train_steps_per_second': 0.733, 'total_flos': 2436286906368000.0, 'train_loss': 3.2522835560334036, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "j4IMiaYS4LHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Examples\n",
        "Used my model shm0007/gpt2-finetuned-agatha-christie which is pushed to huggingface in pipeline() function to generate text. One example was also taken using the model card interface api"
      ],
      "metadata": {
        "id": "Yob3jMi1D4wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "agatha = pipeline(task=\"text-generation\",model=\"shm0007/gpt2-finetuned-agatha-christie\")"
      ],
      "metadata": {
        "id": "jiS8wR79zBx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agatha(\"he stole and\",max_length=110)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzD36slbztY3",
        "outputId": "e2f1f21d-088a-46b3-bb0c-9ba4324d48fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"he stole and looked at the ceiling.\\nHe turned and went upstairs to his work.\\nWhat was the name of the man you had met in South Africa last night?\\nYou heard, then, that the maid’s voice was calling for help?\\nI will never understand!\\nWhat about all this mysterious woman?\\nOh, I mean.\\nYou don't believe me, Mr. Poirot,  said Virginia.\\nBut of course he was a great soldier—and even that he was guilty’s own\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agatha(\"Police came\",max_length=110)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ft7zTvBUBn",
        "outputId": "c0b6fec7-8571-456f-df9c-96115e9985a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Police came forward and took the keys of the car.\\nI knew,  I said, surprised,  that you had.\\nThe doctor stood up and bowed.\\nBut you and the Comte may have got away from those things, sir.\\nHe had arrived at the house in a minute, and the two of them both stood to breakfast.\\nI was the second person at work here.\\nI’m sorry, I’ll see you later.\\nAnd, you see, to know anything is not to be'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agatha(\"President is shot on the head. he is murdered,said\",max_length=110)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za1KxgaAB-QS",
        "outputId": "273e3e63-81f3-435e-82a3-b02be5000837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'President is shot on the head. he is murdered,said Colonel Race.\\nNo one likes to be taken down by the wind.\\nHe is the most efficient, you should guess, _mon ami._    Of course, Mrs. Blair?\\nBut I know the truth.\\nIt was in a book I was working on that day which I had forgotten.\\nThis is your very first visitor to the island.\\nWhat?\\nWhy do you make so many such claims of your own?\\nI’m so'}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agatha(\"How Poirot was killed?\",max_length=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSKbqWgHDSeZ",
        "outputId": "a77af0df-5be6-4956-d48e-44eaed54c264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'How Poirot was killed?\\nIt seemed that he was in all he went wrong.\\nHe had made a brief but amusing impression to myself on many occasions.\\nWe’ll hear about that.\\nThen Tommy’s hand rested upon the edge of the receiver’s pocket-knife.\\nThey were on to a theory that he was a Russian.\\nBut the good Mr. Ackroyd would have preferred it if he had.\\nNo.\\nThere was'}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}